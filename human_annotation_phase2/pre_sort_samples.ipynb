{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-sort samples\n",
    "This notebook filters the model predictions.\n",
    "It filters usages that have incomplete headwords and sorts the remaining usages by theire similarity to the nearest sense.\n",
    "\n",
    "### Usage\n",
    "Set the file paths in the second cell to the predictions of the models you want to filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from spacy.symbols import IS_PUNCT\n",
    "import json\n",
    "from nltk.corpus import wordnet as wn\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_sample_file = \"../data/outputs/model_predictions/sp_f3_100k_historical_unassigned_prediction_sorted_reevaluated.json\"\n",
    "modern_sample_file = \"../data/outputs/model_predictions/SAMPLE_eng_news_2020_1M-sentences-wordnet_sense_id_example[4]_embeddings.json\"\n",
    "\n",
    "\n",
    "output_file = f\"../data/outputs/annotation_phase_2/eng_combined_data.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(165, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "      <th>sentence</th>\n",
       "      <th>target</th>\n",
       "      <th>highest_similarity</th>\n",
       "      <th>corpus_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>unused</td>\n",
       "      <td>During my voyage , affrighted by the dangers w...</td>\n",
       "      <td>[93, 99]</td>\n",
       "      <td>0.223719</td>\n",
       "      <td>ccoha1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>trample</td>\n",
       "      <td>It were less cruel for me to have slain her , ...</td>\n",
       "      <td>[168, 175]</td>\n",
       "      <td>0.251587</td>\n",
       "      <td>ccoha1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>strongly</td>\n",
       "      <td>When the wind blows strongly from the north an...</td>\n",
       "      <td>[20, 28]</td>\n",
       "      <td>0.257914</td>\n",
       "      <td>ccoha1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>warmly</td>\n",
       "      <td>Besides , had it been warmly espoused at the f...</td>\n",
       "      <td>[22, 28]</td>\n",
       "      <td>0.267301</td>\n",
       "      <td>ccoha1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>shirk</td>\n",
       "      <td>to the river and washed , first for , it was i...</td>\n",
       "      <td>[282, 287]</td>\n",
       "      <td>0.267521</td>\n",
       "      <td>ccoha1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        lemma                                           sentence      target  \\\n",
       "0      unused  During my voyage , affrighted by the dangers w...    [93, 99]   \n",
       "49    trample  It were less cruel for me to have slain her , ...  [168, 175]   \n",
       "21   strongly  When the wind blows strongly from the north an...    [20, 28]   \n",
       "26     warmly  Besides , had it been warmly espoused at the f...    [22, 28]   \n",
       "149     shirk  to the river and washed , first for , it was i...  [282, 287]   \n",
       "\n",
       "     highest_similarity corpus_id  \n",
       "0              0.223719    ccoha1  \n",
       "49             0.251587    ccoha1  \n",
       "21             0.257914    ccoha1  \n",
       "26             0.267301    ccoha1  \n",
       "149            0.267521    ccoha1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'lemma': 'unused',\n",
       " 'sentence': 'During my voyage , affrighted by the dangers which surrounded me , and to which I was wholly unused , I heartily repented of my resolution but now , methinks , I have reason to rejoice at my perseverance .',\n",
       " 'target': [93, 99],\n",
       " 'highest_similarity': 0.2237192327980831,\n",
       " 'corpus_id': 'ccoha1'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(historical_sample_file, \"r\") as f:\n",
    "    historical_sample = json.load(f)\n",
    "\n",
    "    complete_historical = []\n",
    "\n",
    "    for lemma in historical_sample:\n",
    "        for usage in historical_sample[lemma]:\n",
    "            if usage['empty_synsets'] == 0:\n",
    "                complete_historical.append({\n",
    "                    \"lemma\": lemma,\n",
    "                    \"sentence\": usage['usage']['sentence'],\n",
    "                    \"target\": usage['usage']['target'],\n",
    "                    \"highest_similarity\": usage['usage']['closest'][0][1],\n",
    "                    \"corpus_id\": f\"ccoha1\"\n",
    "                })\n",
    "\n",
    "complete_historical = pd.DataFrame(complete_historical)\n",
    "complete_historical = complete_historical.drop_duplicates(subset=['sentence'])\n",
    "complete_historical = complete_historical.sort_values(by=['highest_similarity'])\n",
    "\n",
    "print(complete_historical.shape)\n",
    "display(complete_historical.head())\n",
    "\n",
    "historical_dict = complete_historical.to_dict(orient='records')\n",
    "display(historical_dict[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(259, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "      <th>sentence</th>\n",
       "      <th>target</th>\n",
       "      <th>highest_similarity</th>\n",
       "      <th>corpus_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>qualification</td>\n",
       "      <td>Slovan Bratislava's Champions League qualifica...</td>\n",
       "      <td>[37, 50]</td>\n",
       "      <td>0.173049</td>\n",
       "      <td>leipzig_eng_news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>qualification</td>\n",
       "      <td>Streichs team is currently eighth in the 18tea...</td>\n",
       "      <td>[120, 133]</td>\n",
       "      <td>0.188805</td>\n",
       "      <td>leipzig_eng_news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>qualification</td>\n",
       "      <td>But they have fallen away badly, winning only ...</td>\n",
       "      <td>[144, 157]</td>\n",
       "      <td>0.192252</td>\n",
       "      <td>leipzig_eng_news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>qualification</td>\n",
       "      <td>The bid for Aberdeens first Scottish Cup since...</td>\n",
       "      <td>[65, 78]</td>\n",
       "      <td>0.194470</td>\n",
       "      <td>leipzig_eng_news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>wage</td>\n",
       "      <td>Davis gained fame as a state legislator by wag...</td>\n",
       "      <td>[43, 47]</td>\n",
       "      <td>0.194945</td>\n",
       "      <td>leipzig_eng_news</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             lemma                                           sentence  \\\n",
       "70   qualification  Slovan Bratislava's Champions League qualifica...   \n",
       "68   qualification  Streichs team is currently eighth in the 18tea...   \n",
       "67   qualification  But they have fallen away badly, winning only ...   \n",
       "66   qualification  The bid for Aberdeens first Scottish Cup since...   \n",
       "195           wage  Davis gained fame as a state legislator by wag...   \n",
       "\n",
       "         target  highest_similarity         corpus_id  \n",
       "70     [37, 50]            0.173049  leipzig_eng_news  \n",
       "68   [120, 133]            0.188805  leipzig_eng_news  \n",
       "67   [144, 157]            0.192252  leipzig_eng_news  \n",
       "66     [65, 78]            0.194470  leipzig_eng_news  \n",
       "195    [43, 47]            0.194945  leipzig_eng_news  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'lemma': 'qualification',\n",
       " 'sentence': \"Slovan Bratislava's Champions League qualification tie against Faroe Islands side KI Klaksvik has been cancelled after a player from the Slovakian club tested positive for COVID19, European soccer's governing body UEFA said on Saturday.\",\n",
       " 'target': [37, 50],\n",
       " 'highest_similarity': 0.17304900400543594,\n",
       " 'corpus_id': 'leipzig_eng_news'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(modern_sample_file, \"r\") as f:\n",
    "    modern_sample = json.load(f)\n",
    "\n",
    "    complete_modern = []\n",
    "\n",
    "    for lemma in modern_sample:\n",
    "        for usage in modern_sample[lemma]:\n",
    "            if usage['empty_synsets'] == 0:\n",
    "                complete_modern.append({\n",
    "                    \"lemma\": lemma,\n",
    "                    \"sentence\": usage['usage']['sentence'],\n",
    "                    \"target\": usage['usage']['target'],\n",
    "                    \"highest_similarity\": usage['usage']['closest'][0][1],\n",
    "                    \"corpus_id\": f\"leipzig_eng_news\"\n",
    "                })\n",
    "\n",
    "complete_modern = pd.DataFrame(complete_modern)\n",
    "complete_modern = complete_modern.drop_duplicates(subset=['sentence'])\n",
    "complete_modern = complete_modern.sort_values(by=['highest_similarity'])\n",
    "\n",
    "print(complete_modern.shape)\n",
    "display(complete_modern.head())\n",
    "\n",
    "modern_dict = complete_modern.to_dict(orient='records')\n",
    "display(modern_dict[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(424, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "      <th>sentence</th>\n",
       "      <th>target</th>\n",
       "      <th>highest_similarity</th>\n",
       "      <th>corpus_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>unused</td>\n",
       "      <td>During my voyage , affrighted by the dangers w...</td>\n",
       "      <td>[93, 99]</td>\n",
       "      <td>0.223719</td>\n",
       "      <td>ccoha1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trample</td>\n",
       "      <td>It were less cruel for me to have slain her , ...</td>\n",
       "      <td>[168, 175]</td>\n",
       "      <td>0.251587</td>\n",
       "      <td>ccoha1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>strongly</td>\n",
       "      <td>When the wind blows strongly from the north an...</td>\n",
       "      <td>[20, 28]</td>\n",
       "      <td>0.257914</td>\n",
       "      <td>ccoha1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>warmly</td>\n",
       "      <td>Besides , had it been warmly espoused at the f...</td>\n",
       "      <td>[22, 28]</td>\n",
       "      <td>0.267301</td>\n",
       "      <td>ccoha1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>shirk</td>\n",
       "      <td>to the river and washed , first for , it was i...</td>\n",
       "      <td>[282, 287]</td>\n",
       "      <td>0.267521</td>\n",
       "      <td>ccoha1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      lemma                                           sentence      target  \\\n",
       "0    unused  During my voyage , affrighted by the dangers w...    [93, 99]   \n",
       "1   trample  It were less cruel for me to have slain her , ...  [168, 175]   \n",
       "2  strongly  When the wind blows strongly from the north an...    [20, 28]   \n",
       "3    warmly  Besides , had it been warmly espoused at the f...    [22, 28]   \n",
       "4     shirk  to the river and washed , first for , it was i...  [282, 287]   \n",
       "\n",
       "   highest_similarity corpus_id  \n",
       "0            0.223719    ccoha1  \n",
       "1            0.251587    ccoha1  \n",
       "2            0.257914    ccoha1  \n",
       "3            0.267301    ccoha1  \n",
       "4            0.267521    ccoha1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# combine both datasets\n",
    "combined_data = historical_dict + modern_dict\n",
    "combined_data = pd.DataFrame(combined_data)\n",
    "combined_data = combined_data.drop_duplicates(subset=['lemma', 'sentence'])\n",
    "combined_data = combined_data.sort_values(by=['corpus_id', 'highest_similarity'])\n",
    "\n",
    "combined_data.to_json(output_file, orient='records', indent=4)\n",
    "\n",
    "print(combined_data.shape)\n",
    "display(combined_data.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
